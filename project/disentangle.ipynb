{"cells":[{"cell_type":"markdown","metadata":{"id":"4u7nJkbcwSso"},"source":["# SARSCov2 seasonal disentangling with KL annealing\n","\n","Currently, data science and machine learning approaches to understand and predict the development of the COVID-19 pandemic rely on computer vision or time series analysis. Mainly to identify COVID-19 positive cases from chest X-rays or to predict infection dynamics. However, the use of genetic data for machine learning applications remains scarce.\n","\n","Although there are some examples of machine learning modeling of SARS-Cov-2 genome sequences, the genome consists of around 30k bases making it extremely difficult to analyze using modern NLP neural network architectures. The following shows a simple encoding method to analyze large biological sequences and its use for a representation learning task to cluster genomic data. Also how to combine other data sources to understand the meaning of the embedded dimensions.\n"]},{"cell_type":"markdown","metadata":{"id":"IpMxA01GwSsp"},"source":["## Packages"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24662,"status":"ok","timestamp":1713832199148,"user":{"displayName":"Sophie Liu","userId":"11072000168371721717"},"user_tz":240},"id":"Ch6mJOMc4gxI","outputId":"d3fbeef3-29f0-4d07-c6a7-18b5b04e2e16"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26051,"status":"ok","timestamp":1713832225197,"user":{"displayName":"Sophie Liu","userId":"11072000168371721717"},"user_tz":240},"id":"AUarxVTMAsXP","outputId":"20e2ee3b-d3eb-41f7-aa38-f7e90de2c4e0"},"outputs":[],"source":["!pip install Bio"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2022-01-13T21:25:15.3877Z","iopub.status.busy":"2022-01-13T21:25:15.387217Z","iopub.status.idle":"2022-01-13T21:25:21.627822Z","shell.execute_reply":"2022-01-13T21:25:21.627119Z","shell.execute_reply.started":"2022-01-13T21:25:15.387621Z"},"id":"nOjo1dHwwSsq","jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["import re\n","import os\n","import numpy as np\n","import pandas as pd\n","import networkx as nx\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","\n","from Bio import SeqIO\n","from io import StringIO\n","from itertools import product\n","\n","from numpy import linalg as LA\n","from sklearn.cluster import DBSCAN\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import train_test_split\n","\n","from tensorflow import keras\n","\n","from tensorflow.keras.utils import Sequence\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.layers import Input, Activation, Dense,Add,concatenate,LeakyReLU\n","from tensorflow.keras.layers import Conv2D,Conv2DTranspose, Layer,GlobalAveragePooling2D\n","from tensorflow.keras.layers import Flatten, Reshape, BatchNormalization,GlobalMaxPooling2D\n","\n","globalSeed=768\n","\n","from numpy.random import seed\n","seed(globalSeed)\n","\n","tf.compat.v1.set_random_seed(globalSeed)"]},{"cell_type":"markdown","metadata":{"id":"vc5h1PmfwSsq"},"source":["# Working with biological sequences"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2022-01-13T21:25:21.630041Z","iopub.status.busy":"2022-01-13T21:25:21.629735Z","iopub.status.idle":"2022-01-13T21:25:21.658864Z","shell.execute_reply":"2022-01-13T21:25:21.658271Z","shell.execute_reply.started":"2022-01-13T21:25:21.630004Z"},"id":"8uRodRn0wSsq","jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["#Wrapper function to load the sequences.\n","def GetSeqs(Dir):\n","\n","    cDir=Dir\n","\n","    with open(cDir) as file:\n","\n","        seqData=file.read()\n","\n","    Seq=StringIO(seqData)\n","    SeqList=list(SeqIO.parse(Seq,'fasta'))\n","\n","    return SeqList\n","\n","def SplitString(String,ChunkSize):\n","    '''\n","    Split a string ChunkSize fragments using a sliding windiow\n","\n","    Parameters\n","    ----------\n","    String : string\n","        String to be splitted.\n","    ChunkSize : int\n","        Size of the fragment taken from the string .\n","\n","    Returns\n","    -------\n","    Splitted : list\n","        Fragments of the string.\n","\n","    '''\n","    try:\n","        localString=str(String.seq)\n","    except AttributeError:\n","        localString=str(String)\n","\n","    if ChunkSize==1:\n","        Splitted=[val for val in localString]\n","\n","    else:\n","        nCharacters=len(String)\n","        Splitted=[localString[k:k+ChunkSize] for k in range(nCharacters-ChunkSize)]\n","\n","    return Splitted\n","\n","def UniqueToDictionary(UniqueElements):\n","    '''\n","    Creates a dictionary that takes a Unique element as key and return its\n","    position in the UniqueElements array\n","    Parameters\n","    ----------\n","    UniqueElements : List,array\n","        list of unique elements.\n","\n","    Returns\n","    -------\n","    localDictionary : dictionary\n","        Maps element to location.\n","\n","    '''\n","\n","    localDictionary={}\n","    nElements=len(UniqueElements)\n","\n","    for k in range(nElements):\n","        localDictionary[UniqueElements[k]]=k\n","\n","    return localDictionary\n","\n","def CountUniqueElements(UniqueElements,String,Processed=False):\n","    '''\n","    Calculates the frequency of the unique elements in a splited or\n","    processed string. Returns a list with the frequency of the\n","    unique elements.\n","\n","    Parameters\n","    ----------\n","    UniqueElements : array,list\n","        Elements to be analized.\n","    String : strting\n","        Sequence data.\n","    Processed : bool, optional\n","        Controls if the sring is already splitted or not. The default is False.\n","    Returns\n","    -------\n","    localCounter : array\n","        Normalized frequency of each unique fragment.\n","    '''\n","\n","    nUnique=len(UniqueElements)\n","    localCounter=[0 for k in range(nUnique)]\n","\n","    if Processed:\n","        ProcessedString=String\n","    else:\n","        ProcessedString=SplitString(String,len(UniqueElements[0]))\n","\n","    nSeq=len(ProcessedString)\n","    UniqueDictionary=UniqueToDictionary(UniqueElements)\n","\n","    for val in ProcessedString:\n","        if val in UniqueElements:\n","            localPosition=UniqueDictionary[val]\n","            localCounter[localPosition]=localCounter[localPosition]+1\n","\n","    localCounter=[val/nSeq for val in localCounter]\n","\n","    return localCounter\n","\n","def MakeSequenceGraph(Sequence,NodeNames,scheme='A',viz=False):\n","    '''\n","    Creates a graph from a sequence\n","\n","    Parameters\n","    ----------\n","    Sequence : string, sequence object\n","        Sequence to create the graph.\n","    NodeNames : array\n","        Array with the node names or k-mer for each noe.\n","    scheme : string, optional default is A\n","        Controls the connectivity scheme\n","    viz : bool, optional default is False\n","        Controls if the graph is multigraph for analysis or\n","        a simple graph for visualization\n","    Returns\n","    -------\n","    localGraph : networkx graph object\n","        Sequence graph.\n","    '''\n","\n","    Nodes=np.arange(len(NodeNames))\n","    localDict=UniqueToDictionary(NodeNames)\n","\n","    if viz:\n","        localGraph=nx.Graph()\n","    else:\n","        localGraph=nx.MultiGraph()\n","\n","    localGraph.add_nodes_from(Nodes)\n","\n","    if scheme == 'A':\n","\n","        fragmentSize=len(NodeNames[0])\n","        processedSequence=SplitString(Sequence,fragmentSize)\n","\n","        for k in range(len(processedSequence)-1):\n","\n","            if processedSequence[k] in NodeNames and processedSequence[k+1] in NodeNames:\n","\n","                current=localDict[processedSequence[k]]\n","                forward=localDict[processedSequence[k+1]]\n","                localGraph.add_edge(current,forward)\n","\n","    elif scheme == 'B':\n","\n","        fragmentSize=2*len(NodeNames[0])\n","        processedSequence=SplitString(Sequence,fragmentSize)\n","\n","        for frag in processedSequence:\n","\n","            backFragment = frag[0:int(fragmentSize/2)]\n","            forwardFragment = frag[int(fragmentSize/2)::]\n","\n","            if backFragment in NodeNames and forwardFragment in NodeNames:\n","                current = localDict[backFragment]\n","                forward = localDict[forwardFragment]\n","                localGraph.add_edge(current,forward)\n","\n","    return localGraph\n","\n","#Wrapper function to calculate the normalized adjacency matrix\n","def MakeNormAdjacencyMatrix(graph):\n","\n","    matrixShape = (len(graph.nodes),len(graph.nodes))\n","    D12 = np.zeros(matrixShape)\n","\n","    for (node, val) in graph.degree():\n","        D12[node,node] = 1/np.sqrt(val)\n","\n","    A = nx.adjacency_matrix(graph).toarray()\n","    normA = np.dot(D12,A).dot(D12)\n","\n","    w,v = LA.eig(normA)\n","\n","    return normA/LA.norm(w)\n","\n","Alphabet = ['A','C','T','G']\n","Blocks = []\n","\n","maxSize = 4\n","for k in range(1,maxSize):\n","\n","    Blocks.append([''.join(i) for i in product(Alphabet, repeat = k)])\n","\n","#Wrapper function to format the matrix data\n","def MakeSequenceMatrix(sequence,blocks=Blocks):\n","\n","    container = []\n","    mat = np.zeros((64,80))\n","\n","    for blk in blocks:\n","        graphA = MakeSequenceGraph(sequence,blk)\n","        graphB = MakeSequenceGraph(sequence,blk,scheme='B')\n","\n","        a = MakeNormAdjacencyMatrix(graphA)\n","        b = MakeNormAdjacencyMatrix(graphB)\n","\n","        c = a-b\n","        c = (c-c.min())/(c.max()-c.min())\n","        container.append(c)\n","\n","    mat[0:4,0:4] = container[0]\n","    mat[4:20,0:16] = container[1]\n","    mat[0:64,16:80] = container[2]\n","\n","    return mat\n","\n","def GetGridShape(TotalNumberOfElements):\n","    \"\"\"\n","    Parameters\n","    ----------\n","     TotalNumberOfElements : int\n","        Total number of elements in the plot.\n","\n","    Returns\n","    -------\n","    nrows : int\n","        number of rows in the plot.\n","    ncolumns : int\n","        number of columns in the plot.\n","\n","    \"\"\"\n","    numberOfUnique=TotalNumberOfElements\n","    squaredUnique=int(np.sqrt(numberOfUnique))\n","\n","    if squaredUnique*squaredUnique==numberOfUnique:\n","        nrows,ncolumns=squaredUnique,squaredUnique\n","    elif squaredUnique*(squaredUnique+1)<numberOfUnique:\n","        nrows,ncolumns=squaredUnique+1,squaredUnique+1\n","    else:\n","        nrows,ncolumns=squaredUnique,squaredUnique+1\n","\n","    return nrows,ncolumns"]},{"cell_type":"markdown","metadata":{"id":"DEgVb1atwSsr"},"source":["Biological sequences can be categorized into three main groups. DNA sequences, RNA sequences, and protein sequences. Each element in a DNA or RNA sequence represents a nucleoside while the elements of a protein sequence represent an amino acid. From DNA or RNA sequences the corresponding protein sequence can be inferred, but the inverse process is not possible. As the amino acid encoding within the DNA/RNA sequence does not have a one-to-one correspondence. Meaning that single amino acid is encoded in different ways within the DNA/RNA sequence.\n","\n","A DNA or RNA sequence consists of 4 different elements, each element represents a nucleoside or nucleobase inside the DNA or RNA chain. Different three elements combinations of nucleobases lead to specific amino acids. While larger combinations usually correspond to regulatory elements inside the sequence. One of the most common methods to encode a text or biological sequence is to use a binary representation of the sequence or one-hot encoding. However, this type of encoding increases the dimensionality of the data for large sequences.\n","\n","A simple solution to the dimensionality and problem will be to encode the relationship between different elements in the sequence rather than the elements. In a relational encoding scheme, a link is added between two elements if the two elements are consecutive. This simple definition leaves room to process the sequence in different ways creating different encodings of the same sequence.\n","\n","In the case of the SARS Cov 2 sequences, two connectivity schemes are proposed. In the first one, each sequence is divided into k size fragments and a link is added to consecutive fragments in the sequence. While in the second one each sequence is divided into 2k size fragments, then the fragment is divided into two k size fragments and a link is added between the two consecutive fragments. Each connectivity scheme can be visualized as graphs showing specific patterns.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2022-01-13T21:25:21.66447Z","iopub.status.busy":"2022-01-13T21:25:21.664061Z","iopub.status.idle":"2022-01-13T21:25:21.711356Z","shell.execute_reply":"2022-01-13T21:25:21.710748Z","shell.execute_reply.started":"2022-01-13T21:25:21.664437Z"},"id":"4WrUt54LwSss","jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["Sequences = GetSeqs('/content/drive/MyDrive/10708/10708 Project/sequences.fasta')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":807},"execution":{"iopub.execute_input":"2022-01-13T21:25:21.713527Z","iopub.status.busy":"2022-01-13T21:25:21.713267Z","iopub.status.idle":"2022-01-13T21:25:24.535212Z","shell.execute_reply":"2022-01-13T21:25:24.534558Z","shell.execute_reply.started":"2022-01-13T21:25:21.713494Z"},"executionInfo":{"elapsed":3393,"status":"ok","timestamp":1713832455630,"user":{"displayName":"Sophie Liu","userId":"11072000168371721717"},"user_tz":240},"id":"1rtkGebbwSss","outputId":"9c7a4ae3-92f7-49da-94d4-b452f467a1c7","trusted":true},"outputs":[],"source":["Mer01Graph = MakeSequenceGraph(Sequences[0],Blocks[0],viz=True)\n","pos01 = nx.circular_layout(Mer01Graph)\n","\n","Mer02Graph = MakeSequenceGraph(Sequences[0],Blocks[1],viz=True)\n","pos02 = nx.circular_layout(Mer02Graph)\n","\n","Mer03Graph = MakeSequenceGraph(Sequences[0],Blocks[2],viz=True)\n","pos03 = nx.circular_layout(Mer03Graph)\n","\n","Mer01GraphB = MakeSequenceGraph(Sequences[0],Blocks[0],scheme='B',viz=True)\n","pos01B = nx.circular_layout(Mer01Graph)\n","\n","Mer02GraphB = MakeSequenceGraph(Sequences[0],Blocks[1],scheme='B',viz=True)\n","pos02B = nx.circular_layout(Mer02Graph)\n","\n","Mer03GraphB = MakeSequenceGraph(Sequences[0],Blocks[2],scheme='B',viz=True)\n","pos03B = nx.circular_layout(Mer03Graph)\n","\n","f, axs = plt.subplots(2,3,figsize=(15,10))\n","\n","nx.draw_networkx(Mer01Graph, pos=pos01, ax=axs[0,0],alpha=0.5)\n","nx.draw_networkx(Mer02Graph, pos=pos02, ax=axs[0,1],alpha=0.5)\n","nx.draw_networkx(Mer03Graph, pos=pos03, ax=axs[0,2],alpha=0.15)\n","\n","nx.draw_networkx(Mer01GraphB, pos=pos01B, ax=axs[1,0],alpha=0.5)\n","nx.draw_networkx(Mer02GraphB, pos=pos02B, ax=axs[1,1],alpha=0.5)\n","nx.draw_networkx(Mer03GraphB, pos=pos03B, ax=axs[1,2],alpha=0.15)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":139,"status":"ok","timestamp":1713832622921,"user":{"displayName":"Sophie Liu","userId":"11072000168371721717"},"user_tz":240},"id":"ngPp2p-BX_HJ","outputId":"cc670aee-2bd1-40dd-9a36-737daaaf50f3"},"outputs":[],"source":["print(type(pos02))"]},{"cell_type":"markdown","metadata":{"id":"K3OuUb3pwSst"},"source":["As each k relational encoding is defined as a graph, the adjacency matrix will contain the frequency of each connection. This matrix ix normalized with $D^{-\\frac{1}{2}}AD^{-\\frac{1}{2}}$. Where D is the degree matrix and A the adjacency matrix, then this matrix is scaled by dividing it by its Frobenius norm. Then the difference between scheme A and scheme B is used as the final representation for a k size sequence fragment. Arranging the different normalized matrices up to the 3 size fragment results in the following 2D array.\n","\n","This array can be used as a single channel image and use one of the many neural network architectures optimized for computer vision. Another advantage for this kind of encoding is that longe range dependencies in the sequence might be closer in the 2D sequence representation.  "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":541},"execution":{"iopub.execute_input":"2022-01-13T21:25:24.536316Z","iopub.status.busy":"2022-01-13T21:25:24.536101Z","iopub.status.idle":"2022-01-13T21:25:26.560374Z","shell.execute_reply":"2022-01-13T21:25:26.559742Z","shell.execute_reply.started":"2022-01-13T21:25:24.536288Z"},"executionInfo":{"elapsed":2491,"status":"ok","timestamp":1713832644932,"user":{"displayName":"Sophie Liu","userId":"11072000168371721717"},"user_tz":240},"id":"1ChVS6NGwSst","outputId":"ee4d3685-9f66-4d45-fda8-e03966151d9b","trusted":true},"outputs":[],"source":["plt.figure(figsize=(12,6))\n","plt.imshow(MakeSequenceMatrix(Sequences[0]))"]},{"cell_type":"markdown","metadata":{"id":"wPAso-TmwSsu"},"source":["# Dataset generation and subsampling.\n","\n","With a simple sequence representation in place, a subsample of the graph sequence data set is taken as training data. Particularly the sequences isolated in the northeast coast of the USA. Sequence ids approximately match the file names in the Covid-19 Graph Sequences data set. The main difference is that the file names contain the sequence version as stated in the FASTA record of the sequence. While the metadata contains only the sequence id without version."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OCAWx2b2T_54"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":154,"status":"ok","timestamp":1713832681661,"user":{"displayName":"Sophie Liu","userId":"11072000168371721717"},"user_tz":240},"id":"bwk1o72tUbTu","outputId":"dd23a684-4914-4ea7-89df-c9401bea9d7a"},"outputs":[],"source":["%cd \"drive/MyDrive/10708/10708 Project\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":221,"status":"ok","timestamp":1712767443869,"user":{"displayName":"Sophie Liu","userId":"11072000168371721717"},"user_tz":240},"id":"xqxakLYjU4gu","outputId":"8578d7d6-d4d5-47d7-dbc7-fcb4870c79d5"},"outputs":[],"source":["!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VBwBQm1MVmzp"},"outputs":[],"source":["MetaData = pd.read_csv(r'metadata_subset.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":143,"status":"ok","timestamp":1712767453224,"user":{"displayName":"Sophie Liu","userId":"11072000168371721717"},"user_tz":240},"id":"oFJm2nXWV0PM","outputId":"e9dbe75b-ec28-42dc-b16e-5b491e8b3abb"},"outputs":[],"source":["print(MetaData.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"execution":{"iopub.execute_input":"2022-01-13T21:25:26.563072Z","iopub.status.busy":"2022-01-13T21:25:26.561576Z","iopub.status.idle":"2022-01-13T21:25:31.750379Z","shell.execute_reply":"2022-01-13T21:25:31.749722Z","shell.execute_reply.started":"2022-01-13T21:25:26.563031Z"},"executionInfo":{"elapsed":609,"status":"ok","timestamp":1713832688009,"user":{"displayName":"Sophie Liu","userId":"11072000168371721717"},"user_tz":240},"id":"p_ulhbrswSsu","outputId":"d944b015-fc7e-4fde-db70-3370d3ce7eb3","trusted":true},"outputs":[],"source":["MetaData.drop(['PCA_A','PCA_B','VAE_A','VAE_B','ConvVAE_A','ConvVAE_B',],axis=1,inplace=True)\n","MetaData.fillna(0,inplace=True)\n","print(MetaData)\n","USData = MetaData[MetaData['SimplifiedGEO']==\"USA\"]\n","\n","EastCoastDataA = USData[USData[\"geo_long\"]>-85]\n","NorthEastCoast = EastCoastDataA[EastCoastDataA[\"geo_lat\"]>35]\n","\n","plt.figure(figsize=(12,7))\n","plt.hist(NorthEastCoast['outbreaktime'],bins=75,density=True)\n","plt.xlabel('Time')"]},{"cell_type":"markdown","metadata":{"id":"PGW_wOc5wSsu"},"source":["# Network definition"]},{"cell_type":"markdown","metadata":{"id":"_0Ez00eEwSsu"},"source":["Network construction can be divided into three main parts, the convolutional block, the dense bottleneck, and the variational layers. And those components are combined with three wrapper functions. Two merge the networks to create the variational autoencoder, MakeAutoencoder creates an autoencoder without the variational layers, while MakeVariationalAutoencoder defines the variational autoencoder. While CoderByBlock creates the main body of the convolutional autoencoder, it takes a function that creates a simple convolutional network and the number of filters to apply for each convolutional block. This allows changing the main architecture of the network by modifying only one function for fast experimentation.\n","\n","The main convolutional block consists of a dense convolutional network with a LeakyReLU activation function. Downsampling is done by setting strides to (2,2) on the final Conv2D layer within the block and UpSampling by changing the Conv2D layer to Conv2DTranspose with the same strides configuration. The output of this is then connected to a channel and spatial attention module.\n","\n","To dynamically weight the KL loss of the autoencoder a TensorFlow variable is added to the KL layer and trainable is set to false. This incorporates the new variable into the network weights. Then the new variable is changed with a callback at the end of each epoch.\n","\n","Finally, the data is loaded using the sequence class to load and reshape the data."]},{"cell_type":"markdown","metadata":{"id":"vXa4PpuUwSsu"},"source":["### Custom layers"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2022-01-13T21:25:31.751703Z","iopub.status.busy":"2022-01-13T21:25:31.751477Z","iopub.status.idle":"2022-01-13T21:25:31.771609Z","shell.execute_reply":"2022-01-13T21:25:31.770791Z","shell.execute_reply.started":"2022-01-13T21:25:31.751671Z"},"id":"YZj97DfywSsu","jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["class KLDivergenceLayer(Layer):\n","    '''\n","    Custom KL loss layer\n","    '''\n","    def __init__(self,*args,**kwargs):\n","        self.annealing = tf.Variable(0.,dtype=tf.float32,trainable = False)\n","        self.is_placeholder=True\n","        super(KLDivergenceLayer,self).__init__(*args,**kwargs)\n","\n","    def call(self,inputs):\n","\n","        Mu,LogSigma=inputs\n","        klbatch=-0.5*self.annealing*K.sum(1+LogSigma-K.square(Mu)-K.exp(LogSigma),axis=-1)\n","        self.add_loss(K.mean(klbatch),inputs=inputs)\n","        self.add_metric(klbatch,name='kl_loss',aggregation='mean')\n","\n","        return inputs\n","\n","class Sampling(Layer):\n","    '''\n","    Custom sampling layer\n","    '''\n","    def __init__(self, **kwargs):\n","        super().__init__(**kwargs)\n","\n","    def get_config(self):\n","        config = {}\n","        base_config = super().get_config()\n","        return {**base_config, **config}\n","\n","    @tf.autograph.experimental.do_not_convert\n","    def call(self,inputs,**kwargs):\n","\n","        Mu,LogSigma=inputs\n","        batch=tf.shape(Mu)[0]\n","        dim=tf.shape(Mu)[1]\n","        epsilon=K.random_normal(shape=(batch,dim))\n","\n","        return Mu+(K.exp(0.5*LogSigma))*epsilon\n","\n","class SpatialAttention(Layer):\n","    '''\n","    Custom Spatial attention layer\n","    '''\n","\n","    def __init__(self,size, **kwargs):\n","        super(SpatialAttention, self).__init__()\n","        self.size = size\n","        self.kwargs = kwargs\n","\n","    def build(self, input_shapes):\n","        self.conv = Conv2D(filters=1, kernel_size=self.size, strides=1, padding='same')\n","\n","    def call(self, inputs):\n","        pooled_channels = tf.concat(\n","            [tf.math.reduce_max(inputs, axis=3, keepdims=True),\n","            tf.math.reduce_mean(inputs, axis=3, keepdims=True)],\n","            axis=3)\n","\n","        scale = self.conv(pooled_channels)\n","        scale = tf.math.sigmoid(scale)\n","\n","        return inputs * scale\n","\n","class ChannelAttention(Layer):\n","\n","    def __init__(self,**kwargs):\n","        super(ChannelAttention,self).__init__()\n","        self.kwargs = kwargs\n","\n","    def get_config(self):\n","        config = super(ChannelAttention,self).get_config().copy()\n","        config.update({'ratio':self.ratio})\n","        return config\n","\n","    def build(self,input_shape):\n","        channel = input_shape[-1]\n","        self.dense0 = Dense(channel)\n","        self.dense1 = Dense(channel)\n","\n","    def call(self,inputs):\n","\n","        channel = inputs.get_shape().as_list()[-1]\n","\n","        avgpool = GlobalAveragePooling2D()(inputs)\n","        avgpool = Reshape((1,1,channel))(avgpool)\n","        avgpool = self.dense0(avgpool)\n","        avgpool = self.dense1(avgpool)\n","\n","        maxpool = GlobalMaxPooling2D()(inputs)\n","        maxpool = Reshape((1,1,channel))(maxpool)\n","        maxpool = self.dense0(maxpool)\n","        maxpool = self.dense1(maxpool)\n","\n","        feature = Add()([avgpool,maxpool])\n","        feature = Activation('sigmoid')(feature)\n","\n","        return inputs*feature"]},{"cell_type":"markdown","metadata":{"id":"EUlfMjLMwSsv"},"source":["### Network definition"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2022-01-13T21:25:31.774922Z","iopub.status.busy":"2022-01-13T21:25:31.774545Z","iopub.status.idle":"2022-01-13T21:25:31.805085Z","shell.execute_reply":"2022-01-13T21:25:31.804385Z","shell.execute_reply.started":"2022-01-13T21:25:31.774862Z"},"id":"eFu_HGDFwSsv","jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["#Wrapper function, creates a small Functional keras model\n","#Bottleneck of the variational autoencoder\n","def MakeVariationalNetwork(Latent):\n","\n","    InputFunction=Input(shape=(Latent,))\n","    Mu=Dense(Latent)(InputFunction)\n","    LogSigma=Dense(Latent)(InputFunction)\n","    Mu,LogSigma=KLDivergenceLayer(name='KLDivergence')([Mu,LogSigma])\n","    Output=Sampling()([Mu,LogSigma])\n","    variationalBottleneck=Model(inputs=InputFunction,outputs=Output)\n","\n","    return InputFunction,variationalBottleneck\n","\n","def MakeBottleneck(InputShape,Latent,UpSampling=False):\n","    '''\n","    Parameters\n","    ----------\n","    InputShape : tuple\n","        input shape of the previous convolutional layer.\n","    Latent : int\n","        Dimentionality of the latent space.\n","    UpSampling : bool, optional\n","        Controls the sampling behaviour of the network.\n","        The default is False.\n","\n","    Returns\n","    -------\n","    InputFunction : Keras functional model input\n","        input of the network.\n","    localCoder : Keras functional model\n","        Coder model, transition layer of the bottleneck.\n","\n","    '''\n","\n","    productUnits = np.product(InputShape)\n","    Units = [productUnits,productUnits//4,productUnits//16,Latent]\n","\n","    if UpSampling:\n","        finalUnits = Units[::-1]\n","        InputFunction = Input(shape=(Latent,))\n","        X = Dense(finalUnits[0],use_bias=False)(InputFunction)\n","\n","    else:\n","        finalUnits = Units\n","        InputFunction = Input(shape=InputShape)\n","        X = Flatten()(InputFunction)\n","        X = Dense(finalUnits[0],use_bias=False)(X)\n","\n","\n","    X = BatchNormalization()(X)\n","    X = LeakyReLU()(X)\n","\n","    for k in range(1,len(Units)-1):\n","\n","        X = Dense(finalUnits[k],use_bias=False)(X)\n","        X = BatchNormalization()(X)\n","        X = LeakyReLU()(X)\n","\n","    X = Dense(finalUnits[-1],use_bias=False)(X)\n","\n","    if UpSampling:\n","        X=LeakyReLU()(X)\n","        Output=Reshape(InputShape)(X)\n","    else:\n","        Output=LeakyReLU()(X)\n","\n","    Bottleneck=Model(inputs=InputFunction,outputs=Output)\n","\n","    return InputFunction,Bottleneck\n","\n","def MakeConvolutionBlock(X, Convolutions):\n","\n","    X = Conv2D(Convolutions, (3, 3), padding='same',use_bias=False)(X)\n","    X = BatchNormalization()(X)\n","    X = LeakyReLU()(X)\n","\n","    return X\n","\n","def MakeDenseBlock(x, Convolutions,Depth):\n","\n","    concat_feat= x\n","    for i in range(Depth):\n","        x = MakeConvolutionBlock(concat_feat,Convolutions)\n","        concat_feat=concatenate([concat_feat,x])\n","\n","    return concat_feat\n","\n","def SamplingBlock(X,Units,Depth,UpSampling=False):\n","\n","    X = MakeDenseBlock(X,Units,Depth)\n","\n","    if UpSampling:\n","        X = Conv2DTranspose(Units,(3,3),strides=(2,2),padding='same',use_bias=False)(X)\n","    else:\n","        X = Conv2D(Units,(3,3),strides=(2,2),padding='same',use_bias=False)(X)\n","\n","    X = ChannelAttention()(X)\n","    X = SpatialAttention(3)(X)\n","\n","    X = BatchNormalization()(X)\n","    X = LeakyReLU()(X)\n","\n","    return X\n","\n","def CoderByBlock(InputShape,Units,Depth,UpSampling=False):\n","\n","    if UpSampling:\n","        Units=Units[::-1]\n","    else:\n","        Units=Units\n","\n","    InputFunction = Input(shape=InputShape)\n","    X = SamplingBlock(InputFunction,Units[0],Depth,UpSampling=UpSampling)\n","\n","    for k in range(1,len(Units)-1):\n","\n","        if Depth-k+1 <= 1:\n","            blockSize = 2\n","        else:\n","            blockSize = Depth-k\n","\n","        X = SamplingBlock(X,Units[k],blockSize,UpSampling=UpSampling)\n","\n","    if UpSampling:\n","        X = Conv2D(1,(3,3),padding='same',use_bias=False)(X)\n","        Output = Activation('sigmoid')(X)\n","    else:\n","        X = Conv2D(Units[-1],(3,3),padding='same',use_bias=False)(X)\n","        Output = LeakyReLU()(X)\n","\n","    coderModel = Model(inputs=InputFunction,outputs=Output)\n","\n","    return InputFunction,coderModel\n","\n","#Wrapper function joins the Coder function and the bottleneck function\n","#to create a simple autoencoder\n","def MakeAutoencoder(CoderFunction,InputShape,Units,BlockSize,**kwargs):\n","\n","    InputEncoder,Encoder=CoderFunction(InputShape,Units,BlockSize,**kwargs)\n","    EncoderOutputShape=Encoder.layers[-1].output_shape\n","    BottleneckInputShape=EncoderOutputShape[1::]\n","    InputBottleneck,Bottleneck=MakeBottleneck(BottleneckInputShape,2)\n","    ConvEncoderOutput=Bottleneck(Encoder(InputEncoder))\n","\n","    ConvEncoder=Model(inputs=InputEncoder,outputs=ConvEncoderOutput)\n","\n","    rInputBottleneck,rBottleneck=MakeBottleneck(BottleneckInputShape,2,UpSampling=True)\n","    InputDecoder,Decoder=CoderFunction(BottleneckInputShape,Units,BlockSize,UpSampling=True,**kwargs)\n","    ConvDecoderOutput=Decoder(rBottleneck(rInputBottleneck))\n","    ConvDecoder=Model(inputs=rInputBottleneck,outputs=ConvDecoderOutput)\n","\n","    ConvAEoutput=ConvDecoder(ConvEncoder(InputEncoder))\n","    ConvAE=Model(inputs=InputEncoder,outputs=ConvAEoutput)\n","\n","    return InputEncoder,InputDecoder,ConvEncoder,ConvDecoder,ConvAE\n","\n","# Wrapper functon, joins the autoencoder function with the custom variational\n","#layers to create an autoencoder\n","def MakeVariationalAutoencoder(CoderFunction,InputShape,Units,BlockSize,**kwargs):\n","\n","    InputEncoder,InputDecoder,ConvEncoder,ConvDecoder,_=MakeAutoencoder(CoderFunction,InputShape,Units,BlockSize,**kwargs)\n","\n","    InputVAE,VAE=MakeVariationalNetwork(2)\n","    VAEencoderOutput=VAE(ConvEncoder(InputEncoder))\n","    ConvVAEencoder=Model(inputs=InputEncoder,outputs=VAEencoderOutput)\n","\n","    VAEOutput=ConvDecoder(ConvVAEencoder(InputEncoder))\n","    ConvVAEAE=Model(inputs=InputEncoder,outputs=VAEOutput)\n","\n","    return InputEncoder,InputDecoder,ConvVAEencoder,ConvDecoder,ConvVAEAE"]},{"cell_type":"markdown","metadata":{"id":"cTBVqkDgwSsv"},"source":["### Auxiliary functions"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2022-01-13T21:25:31.806543Z","iopub.status.busy":"2022-01-13T21:25:31.806295Z","iopub.status.idle":"2022-01-13T21:25:31.827049Z","shell.execute_reply":"2022-01-13T21:25:31.826295Z","shell.execute_reply.started":"2022-01-13T21:25:31.80651Z"},"id":"uWy6cyaawSsv","jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["class DataSequence(Sequence):\n","\n","    def __init__(self, x_set,batch_size):\n","        self.x = x_set\n","        self.batch_size = batch_size\n","\n","    def __len__(self):\n","        return int(np.ceil(len(self.x)/self.batch_size))\n","\n","    def __data_generation(self, dirList):\n","\n","        X = np.array([np.load(val) for val in dirList])\n","        X = X.reshape((-1,64,80,1))\n","        y = X\n","\n","        return X,y\n","\n","    def __getitem__(self,idx):\n","        batch_x = self.x[idx*self.batch_size:(idx+1)*self.batch_size]\n","        X, y = self.__data_generation(batch_x)\n","\n","        return X,y\n","\n","class KLAnnealing(keras.callbacks.Callback):\n","\n","    def __init__(self,position, weigths):\n","        super().__init__()\n","        self.position = position\n","        self.weigths = tf.Variable(weigths,trainable=False,dtype=tf.float32)\n","\n","    def on_epoch_end(self, epoch,logs=None):\n","\n","        weights = self.model.get_weights()\n","        weights[self.position] = self.weigths[epoch]\n","        self.model.set_weights(weights)\n","\n","\n","def MakeAnnealingWeights(epochs,cycles,scale=1):\n","\n","    pointspercycle = epochs//cycles\n","    AnnealingWeights = 1*(1/(1+np.exp(-1*np.linspace(-10,10,num=pointspercycle))))\n","\n","    for k in range(cycles-1):\n","        AnnealingWeights = np.append(AnnealingWeights,1*(1/(1+np.exp(-1*np.linspace(-10,10,num=pointspercycle+1)))))\n","\n","    return scale*AnnealingWeights"]},{"cell_type":"markdown","metadata":{"id":"D2osoIM2wSsw"},"source":["# Training"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2022-01-13T21:25:31.831637Z","iopub.status.busy":"2022-01-13T21:25:31.831404Z","iopub.status.idle":"2022-01-13T21:25:46.971422Z","shell.execute_reply":"2022-01-13T21:25:46.970624Z","shell.execute_reply.started":"2022-01-13T21:25:31.831603Z"},"executionInfo":{"elapsed":7947,"status":"ok","timestamp":1713832862971,"user":{"displayName":"Sophie Liu","userId":"11072000168371721717"},"user_tz":240},"id":"pSxf6Gm-wSsw","jupyter":{"source_hidden":true},"outputId":"4e2f532f-fdc3-418f-a796-e1251dcc3d2c","trusted":true},"outputs":[],"source":[" matrixData = '/content/drive/MyDrive/10708/10708 Project/featuresdata_subset'\n","\n","fileNames = os.listdir(matrixData)\n","northNames = [val+'.1.npy' for val in NorthEastCoast['id']]\n","finalNamesNorth = list(set(northNames).intersection(fileNames))\n","pathsNorth = np.array([matrixData+'/'+val for val in finalNamesNorth])\n","\n","input_shape = (64,80,1)\n","Arch = [12,24,36,48,36]\n","Depth = 4\n","\n","lr = 0.0001\n","minlr = 0.000001\n","epochs = 30\n","batch_size = 128\n","decay = 2*(lr-minlr)/epochs\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10477,"status":"ok","timestamp":1713833202368,"user":{"displayName":"Sophie Liu","userId":"11072000168371721717"},"user_tz":240},"id":"HNDRyrEXZudW","outputId":"ccb6ac5e-d310-47ca-debd-abf2f6c63c85"},"outputs":[],"source":["AnnealingWeights = MakeAnnealingWeights(epochs,4,scale=0.00001)\n","\n","_,_,Encoder,Decoder,AE = MakeVariationalAutoencoder(CoderByBlock,input_shape,Arch,Depth)\n","\n","print(AnnealingWeights)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pu9bNxWSav-2"},"outputs":[],"source":["AE.summary()\n","KLAposition = [k for k,val in enumerate(AE.get_weights()) if len(val.shape)==0][0]\n","\n","trainPaths,testPaths,_,_ = train_test_split(pathsNorth,pathsNorth,test_size=0.1, random_state=42)\n","\n","FullLoad = DataSequence(pathsNorth,batch_size)\n","TrainLoad = DataSequence(trainPaths,batch_size)\n","TestLoad = DataSequence(testPaths,batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"colab":{"base_uri":"https://localhost:8080/","height":495},"execution":{"iopub.execute_input":"2022-01-13T21:25:46.973192Z","iopub.status.busy":"2022-01-13T21:25:46.972759Z","iopub.status.idle":"2022-01-14T00:36:17.750315Z","shell.execute_reply":"2022-01-14T00:36:17.748915Z","shell.execute_reply.started":"2022-01-13T21:25:46.973153Z"},"executionInfo":{"elapsed":1218794,"status":"error","timestamp":1713801694033,"user":{"displayName":"Sophie Liu","userId":"11072000168371721717"},"user_tz":240},"id":"d7gYE6aCwSsw","outputId":"45f2ee00-0fb1-43c5-d8ed-7220ef2b4f44","trusted":true},"outputs":[],"source":["AE.compile(Adam(learning_rate=lr),loss='mse')\n","history =  AE.fit(TrainLoad,epochs=epochs,\n","                  validation_data=TestLoad,workers=8,\n","                  callbacks=[KLAnnealing(KLAposition,AnnealingWeights)])\n","\n","VariationalRepresentationNorth = Encoder.predict(FullLoad)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":42752,"status":"ok","timestamp":1713801740021,"user":{"displayName":"Sophie Liu","userId":"11072000168371721717"},"user_tz":240},"id":"6lXfnmcwsklI","outputId":"7a4561b1-e0f3-4a03-d89b-b4636e189578"},"outputs":[],"source":["VariationalRepresentationNorth = Encoder.predict(FullLoad)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14079,"status":"ok","timestamp":1713801807317,"user":{"displayName":"Sophie Liu","userId":"11072000168371721717"},"user_tz":240},"id":"R6rh9UZdsK8K","outputId":"a38acbc5-38f8-48c1-a262-2de172feec9c"},"outputs":[],"source":["!pip install joblib\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4290,"status":"ok","timestamp":1712783684784,"user":{"displayName":"Sophie Liu","userId":"11072000168371721717"},"user_tz":240},"id":"5nEoEUmc3K9Q","outputId":"1e9bd64f-02ee-405e-af96-465ed74020b0"},"outputs":[],"source":["!pip install pickle"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":321},"executionInfo":{"elapsed":393,"status":"error","timestamp":1712784624473,"user":{"displayName":"Sophie Liu","userId":"11072000168371721717"},"user_tz":240},"id":"lB3IEo9jzmDe","outputId":"51465440-8b65-4024-c485-958a88c8dc6f"},"outputs":[],"source":["import pickle as pkl\n","import tensorflow as tf\n","\n","with open(\"model.pkl\", \"wb\") as f:\n","  pkl.dump(history, f)"]},{"cell_type":"markdown","metadata":{"id":"CfB5Pqd-wSsw"},"source":["# Adding the metadata"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2022-01-14T00:36:17.752567Z","iopub.status.busy":"2022-01-14T00:36:17.751495Z","iopub.status.idle":"2022-01-14T00:36:18.073376Z","shell.execute_reply":"2022-01-14T00:36:18.072607Z","shell.execute_reply.started":"2022-01-14T00:36:17.752526Z"},"id":"5YQRfc_5wSsw","jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["NorthDataSet = NorthEastCoast.set_index('id')\n","NorthIds = [val[0:-6] for val in finalNamesNorth]\n","NorthDataSet = NorthDataSet.loc[NorthIds]\n","NorthDataSet[\"latentA\"] = VariationalRepresentationNorth[:,0]\n","NorthDataSet[\"latentB\"] = VariationalRepresentationNorth[:,1]"]},{"cell_type":"markdown","metadata":{"id":"wWTMW8C0wSsw"},"source":["To understand the encoded meaning of the learned representations we can add new metadata and encode that information. One simple visual technique will be to color code the isolation date of the different SARS Cov 2 sequences. This will visually show any kind of pattern in the data."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":539},"execution":{"iopub.execute_input":"2022-01-14T00:36:18.078288Z","iopub.status.busy":"2022-01-14T00:36:18.077897Z","iopub.status.idle":"2022-01-14T00:36:23.583151Z","shell.execute_reply":"2022-01-14T00:36:23.58118Z","shell.execute_reply.started":"2022-01-14T00:36:18.078247Z"},"executionInfo":{"elapsed":961,"status":"ok","timestamp":1713801808262,"user":{"displayName":"Sophie Liu","userId":"11072000168371721717"},"user_tz":240},"id":"jDGqHjRHwSsw","outputId":"e0c964db-3347-4d67-feef-cdb319ee7b58","trusted":true},"outputs":[],"source":["plt.figure(figsize=(16,6))\n","plt.scatter(NorthDataSet[\"latentA\"],NorthDataSet[\"latentB\"],c=NorthDataSet['week'],alpha=0.15)"]},{"cell_type":"markdown","metadata":{"id":"Muvm4e_8wSsw"},"source":["Another technique will be to analyze the different clusters in the representation. Clustering by itself might not provide a definitive answer, but it could help us to analyze each cluster individually."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":454},"executionInfo":{"elapsed":156,"status":"ok","timestamp":1713805545492,"user":{"displayName":"Sophie Liu","userId":"11072000168371721717"},"user_tz":240},"id":"RGuaOtvIxUla","outputId":"eaca7452-6c39-48a7-f8e4-f4f596b79d09"},"outputs":[],"source":["NorthDataSet[['latentA','latentB']]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-14T00:46:11.336361Z","iopub.status.busy":"2022-01-14T00:46:11.335795Z","iopub.status.idle":"2022-01-14T00:46:13.611953Z","shell.execute_reply":"2022-01-14T00:46:13.611181Z","shell.execute_reply.started":"2022-01-14T00:46:11.336323Z"},"id":"a8POCXBvwSsx","trusted":true},"outputs":[],"source":["ConvVAEkmeans =  DBSCAN(eps=0.25,min_samples=10,algorithm='ball_tree',metric='euclidean',n_jobs=-2).fit(NorthDataSet[['latentA','latentB']])\n","clustersLabels,counts = np.unique(ConvVAEkmeans.labels_,return_counts=True)\n","clabels = []\n","\n","for val,sal in zip(clustersLabels,counts):\n","    if sal>500 and val!=-1:\n","        clabels.append(val)#removes outliers and low populated clusters\n","\n","localColors = [plt.cm.seismic(val) for val in np.linspace(0,1,num=len(clabels))]\n","NorthDataSet['CLabels'] = [val if val in clabels else -1 for val in ConvVAEkmeans.labels_]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":152,"status":"ok","timestamp":1713805679968,"user":{"displayName":"Sophie Liu","userId":"11072000168371721717"},"user_tz":240},"id":"4l9Oj8DaxKSg","outputId":"46f792b7-3709-42d3-8584-3678097c6756"},"outputs":[],"source":["print(np.unique(ConvVAEkmeans.labels_,return_counts=True)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":833},"execution":{"iopub.execute_input":"2022-01-14T00:46:18.34485Z","iopub.status.busy":"2022-01-14T00:46:18.34459Z","iopub.status.idle":"2022-01-14T00:46:21.302341Z","shell.execute_reply":"2022-01-14T00:46:21.287865Z","shell.execute_reply.started":"2022-01-14T00:46:18.344818Z"},"executionInfo":{"elapsed":1649,"status":"ok","timestamp":1713805692722,"user":{"displayName":"Sophie Liu","userId":"11072000168371721717"},"user_tz":240},"id":"vh3do0exwSsx","outputId":"aa145326-74d8-4666-f010-d3fa358aca5a","trusted":true},"outputs":[],"source":["plt.figure(figsize=(18,10))\n","\n","gs = plt.GridSpec(2,len(clabels))\n","ax0 = plt.subplot(gs[0,:])\n","\n","for k,col in zip(clabels,localColors):\n","    ax0.scatter(NorthDataSet[NorthDataSet['CLabels']==k]['latentA'],NorthDataSet[NorthDataSet['CLabels']==k]['latentB'],c=col,alpha=0.0125)\n","\n","ax0.scatter(NorthDataSet[NorthDataSet['CLabels']==-1]['latentA'],NorthDataSet[NorthDataSet['CLabels']==-1]['latentB'],c='black',alpha=0.0125)\n","ax0.set_title('Masha',loc='right')\n","\n","k=0\n","for clust,colr in zip(clabels,localColors):\n","\n","    axes = plt.subplot(gs[1,k])\n","    axes.hist(NorthDataSet[NorthDataSet['CLabels']==clust]['week'],bins=50,color='blue')\n","    k=k+1\n","\n","plt.tight_layout()"]},{"cell_type":"markdown","metadata":{"id":"nzu3grx5wSsx"},"source":["One simple analysis of the cluster information will be to measure the quantity of each of the different nucleobases in the sequence and how they change from cluster to cluster. And how that content changes through time within each cluster, dividing the cluster into two periods, the first half of the year and the second half of the year."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-14T00:46:34.633623Z","iopub.status.busy":"2022-01-14T00:46:34.633332Z","iopub.status.idle":"2022-01-14T00:47:24.887522Z","shell.execute_reply":"2022-01-14T00:47:24.885963Z","shell.execute_reply.started":"2022-01-14T00:46:34.633591Z"},"id":"RUhXw7OZwSsx","trusted":true},"outputs":[],"source":["KmersData = pd.read_csv('kmer_subset.csv')\n","KmersData['id'] = [val[0:-2] for val in KmersData['id']]\n","KmersData = KmersData.set_index('id')\n","\n","nrows,ncolumns = GetGridShape(len(clabels))\n","subPlotIndexs=[(j,k) for j in range(nrows) for k in range(ncolumns)]"]},{"cell_type":"markdown","metadata":{"id":"LBT7DBd1wSsx"},"source":["## Adenine Shift"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":167,"status":"ok","timestamp":1713805776936,"user":{"displayName":"Sophie Liu","userId":"11072000168371721717"},"user_tz":240},"id":"DspH-ZQayMp1","outputId":"55419d7e-0c7b-44d7-ff19-bbf46d80221b"},"outputs":[],"source":["print(f\"nrows: {nrows}, ncolumns: {ncolumns}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"colab":{"base_uri":"https://localhost:8080/","height":1000},"execution":{"iopub.execute_input":"2022-01-14T00:47:30.418147Z","iopub.status.busy":"2022-01-14T00:47:30.417814Z","iopub.status.idle":"2022-01-14T00:47:36.278268Z","shell.execute_reply":"2022-01-14T00:47:36.277514Z","shell.execute_reply.started":"2022-01-14T00:47:30.418096Z"},"executionInfo":{"elapsed":794,"status":"error","timestamp":1713805703036,"user":{"displayName":"Sophie Liu","userId":"11072000168371721717"},"user_tz":240},"id":"QXGnhTqEwSsx","outputId":"8eae2bd0-3cf3-4147-f0b5-19253ddabf88","trusted":true},"outputs":[],"source":["fig,axes=plt.subplots(nrows,ncolumns,figsize=(15,12),sharex=True)\n","for k,kal in enumerate(clabels):\n","\n","    clusterData = NorthDataSet[NorthDataSet['CLabels']==kal]\n","    low = clusterData[clusterData['week']<0.5].index\n","    high = clusterData[clusterData['week']>0.5].index\n","    axes[subPlotIndexs[k]].hist(KmersData['A'].loc[high],color='red',bins=100,density=True,label='Cluster = '+str(kal))\n","    axes[subPlotIndexs[k]].hist(KmersData['A'].loc[low],color='red',bins=100,alpha=0.5,density=True,label='Cluster = '+str(kal))\n","    axes[subPlotIndexs[k]].set_xlim([0.05,0.15])\n","    axes[subPlotIndexs[k]].set_xlabel('Nucleotide content')\n","    axes[subPlotIndexs[k]].set_title('Cluster = ' + str(kal))\n","fig.suptitle('Adenine shift',x=0.9,y=0.9)"]},{"cell_type":"markdown","metadata":{"id":"Si5W73U2wSsx"},"source":["## Cytosine shift"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"colab":{"base_uri":"https://localhost:8080/","height":1000},"execution":{"iopub.execute_input":"2022-01-14T00:47:45.918001Z","iopub.status.busy":"2022-01-14T00:47:45.917727Z","iopub.status.idle":"2022-01-14T00:47:50.738828Z","shell.execute_reply":"2022-01-14T00:47:50.738065Z","shell.execute_reply.started":"2022-01-14T00:47:45.917971Z"},"executionInfo":{"elapsed":399,"status":"error","timestamp":1713805705997,"user":{"displayName":"Sophie Liu","userId":"11072000168371721717"},"user_tz":240},"id":"fTBSMDeYwSsx","outputId":"8b454e9b-9533-45b0-cf8f-79bac3a6541a","trusted":true},"outputs":[],"source":["fig,axes=plt.subplots(nrows,ncolumns,figsize=(15,12),sharex=True)\n","for k,kal in enumerate(clabels):\n","\n","    clusterData = NorthDataSet[NorthDataSet['CLabels']==kal]\n","    low = clusterData[clusterData['week']<0.5].index\n","    high = clusterData[clusterData['week']>0.5].index\n","    axes[subPlotIndexs[k]].hist(KmersData['C'].loc[high],color='blue',bins=100,density=True,label='Cluster = '+str(kal))\n","    axes[subPlotIndexs[k]].hist(KmersData['C'].loc[low],color='blue',bins=100,alpha=0.5,density=True,label='Cluster = '+str(kal))\n","    axes[subPlotIndexs[k]].set_xlim([0.2,0.35])\n","    axes[subPlotIndexs[k]].set_xlabel('Nucleotide content')\n","    axes[subPlotIndexs[k]].set_title('Cluster = ' + str(kal))\n","\n","fig.suptitle('Cytosine shift',x=0.9,y=0.9)"]},{"cell_type":"markdown","metadata":{"id":"-7YnOY4KwSsy"},"source":["## Guanine shift"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2022-01-14T00:48:00.588712Z","iopub.status.busy":"2022-01-14T00:48:00.588454Z","iopub.status.idle":"2022-01-14T00:48:05.581206Z","shell.execute_reply":"2022-01-14T00:48:05.580476Z","shell.execute_reply.started":"2022-01-14T00:48:00.588683Z"},"id":"q9hJMu5xwSsy","trusted":true},"outputs":[],"source":["fig,axes=plt.subplots(nrows,ncolumns,figsize=(15,12),sharex=True)\n","for k,kal in enumerate(clabels):\n","\n","    clusterData = NorthDataSet[NorthDataSet['CLabels']==kal]\n","    low = clusterData[clusterData['week']<0.5].index\n","    high = clusterData[clusterData['week']>0.5].index\n","    axes[subPlotIndexs[k]].hist(KmersData['G'].loc[high],color='green',bins=100,density=True,label='Cluster = '+str(kal))\n","    axes[subPlotIndexs[k]].hist(KmersData['G'].loc[low],color='green',bins=100,alpha=0.5,density=True,label='Cluster = '+str(kal))\n","    axes[subPlotIndexs[k]].set_xlim([0.75,0.85])\n","    axes[subPlotIndexs[k]].set_xlabel('Nucleotide content')\n","    axes[subPlotIndexs[k]].set_title('Cluster = ' + str(kal))\n","fig.suptitle('Guanine shift',x=0.9,y=0.9)"]},{"cell_type":"markdown","metadata":{"id":"RtNbB2MywSs2"},"source":["## Thymine/Uracil shift"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2022-01-14T00:48:17.176324Z","iopub.status.busy":"2022-01-14T00:48:17.175762Z","iopub.status.idle":"2022-01-14T00:48:22.592609Z","shell.execute_reply":"2022-01-14T00:48:22.591826Z","shell.execute_reply.started":"2022-01-14T00:48:17.176283Z"},"id":"F1el012KwSs3","trusted":true},"outputs":[],"source":["fig,axes=plt.subplots(nrows,ncolumns,figsize=(15,12),sharex=True)\n","for k,kal in enumerate(clabels):\n","\n","    clusterData = NorthDataSet[NorthDataSet['CLabels']==kal]\n","    low = clusterData[clusterData['week']<0.5].index\n","    high = clusterData[clusterData['week']>0.5].index\n","    axes[subPlotIndexs[k]].hist(KmersData['T'].loc[high],color='black',bins=100,density=True,label='Cluster = '+str(kal))\n","    axes[subPlotIndexs[k]].hist(KmersData['T'].loc[low],color='black',bins=100,alpha=0.5,density=True,label='Cluster = '+str(kal))\n","    axes[subPlotIndexs[k]].set_xlim([0.7,0.8])\n","    axes[subPlotIndexs[k]].set_xlabel('Nucleotide content')\n","    axes[subPlotIndexs[k]].set_title('Cluster = ' + str(kal))\n","fig.suptitle('Thymine/Uracil shift',x=0.9,y=0.9)"]},{"cell_type":"markdown","metadata":{"id":"4ccCiLLRwSs3"},"source":["From the nucleobase content analysis, a clear shift in the content of Cytosine and Thymine/Uracil is found on every cluster. This particular characteristic might be useful for other interventions."]},{"cell_type":"markdown","metadata":{"id":"tninmgXzwSs3"},"source":["# Adding infection dynamics\n","\n","Another kind of metadata to add to the learned representations is the dynamics of the cases in the particular region. Three states will be taken as examples and the total cases per week are plotted against the mean value of each data point in that week from that state. To add the dynamics of the process, the cases rate and acceleration are also compared. This hopefully results in additional information encoded in the learned representation."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"execution":{"iopub.execute_input":"2022-01-14T00:48:31.648059Z","iopub.status.busy":"2022-01-14T00:48:31.647505Z","iopub.status.idle":"2022-01-14T00:48:31.901619Z","shell.execute_reply":"2022-01-14T00:48:31.900853Z","shell.execute_reply.started":"2022-01-14T00:48:31.648019Z"},"executionInfo":{"elapsed":163,"status":"error","timestamp":1713805790472,"user":{"displayName":"Sophie Liu","userId":"11072000168371721717"},"user_tz":240},"id":"b8hWfDNOwSs3","outputId":"e84d859f-d416-453b-ee76-a42ecdabb4d8","trusted":true},"outputs":[],"source":["USAInfectionData = pd.read_csv('../input/us-covid19-dataset-live-hourlydaily-updates/States.csv')\n","USAInfectionData[\"datets\"] = pd.to_datetime(USAInfectionData['date'],format='%Y-%m-%d')\n","USAInfectionData[\"year\"] = USAInfectionData[\"datets\"].dt.year\n","USAInfectionData[\"week\"] = USAInfectionData[\"datets\"].dt.isocalendar().week\n","USAInfection2021 = USAInfectionData[USAInfectionData[\"year\"]==2021]\n","\n","GetDataByState = lambda state : np.array(USAInfection2021[USAInfection2021[\"state\"]==state].groupby(\"week\")[\"cases\"].sum())[0:-2]\n","\n","States = [\"Maine\",\"Vermont\",\"New Hampshire\",\"Massachusetts\",\"Rhode Island\",\"New York\",\"Connecticut\",\n","         \"New Jersey\",\"Pennsylvania\",\"Delaware\"]\n","\n","StateData = np.array([GetDataByState(st)/GetDataByState(st).max() for st in States])"]},{"cell_type":"markdown","metadata":{"id":"TuNiTrrIwSs4"},"source":["## New York"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2022-01-14T00:48:37.822269Z","iopub.status.busy":"2022-01-14T00:48:37.821535Z","iopub.status.idle":"2022-01-14T00:48:39.021308Z","shell.execute_reply":"2022-01-14T00:48:39.020496Z","shell.execute_reply.started":"2022-01-14T00:48:37.82223Z"},"id":"IxLswFkAwSs4","trusted":true},"outputs":[],"source":["localData = NorthDataSet[NorthDataSet[\"Geo_Location\"]==\"USA: New York\"]\n","\n","fig,axs = plt.subplots(3,3,figsize=(20,10))\n","\n","for st in StateData:\n","\n","    axs[0,0].plot(st,color=\"gray\")\n","    axs[0,1].plot(np.diff(st,n=1),color=\"gray\")\n","    axs[0,2].plot(np.diff(st,n=2),color=\"gray\")\n","\n","axs[0,0].plot(StateData[5],color=\"red\")\n","axs[0,1].plot(np.diff(StateData[5],n=1),color=\"red\")\n","axs[0,2].plot(np.diff(StateData[5],n=2),color=\"red\")\n","\n","axs[1,0].plot(StateData[5],np.array(localData.groupby(\"week\")[\"latentA\"].mean()),'bo')\n","axs[1,1].plot(np.diff(StateData[5],n=1),np.array(localData.groupby(\"week\")[\"latentA\"].mean())[0:-1],'bo')\n","axs[1,2].plot(np.diff(StateData[5],n=2),np.array(localData.groupby(\"week\")[\"latentA\"].mean())[0:-2],'bo')\n","\n","axs[2,0].plot(StateData[5],np.array(localData.groupby(\"week\")[\"latentB\"].mean()),'bo')\n","axs[2,1].plot(np.diff(StateData[5],n=1),np.array(localData.groupby(\"week\")[\"latentB\"].mean())[0:-1],'bo')\n","axs[2,2].plot(np.diff(StateData[5],n=2),np.array(localData.groupby(\"week\")[\"latentB\"].mean())[0:-2],'bo')"]},{"cell_type":"markdown","metadata":{"id":"8n3lsfHdwSs4"},"source":["## Massachusetts"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2022-01-14T00:48:52.676607Z","iopub.status.busy":"2022-01-14T00:48:52.676343Z","iopub.status.idle":"2022-01-14T00:48:53.965627Z","shell.execute_reply":"2022-01-14T00:48:53.964944Z","shell.execute_reply.started":"2022-01-14T00:48:52.676578Z"},"id":"0CBy5cvFwSs4","trusted":true},"outputs":[],"source":["localData = NorthDataSet[NorthDataSet[\"Geo_Location\"]==\"USA: Massachusetts\"]\n","\n","fig,axs = plt.subplots(3,3,figsize=(20,10))\n","\n","for st in StateData:\n","\n","    axs[0,0].plot(st,color=\"gray\")\n","    axs[0,1].plot(np.diff(st,n=1),color=\"gray\")\n","    axs[0,2].plot(np.diff(st,n=2),color=\"gray\")\n","\n","axs[0,0].plot(StateData[3],color=\"red\")\n","axs[0,1].plot(np.diff(StateData[3],n=1),color=\"red\")\n","axs[0,2].plot(np.diff(StateData[3],n=2),color=\"red\")\n","\n","axs[1,0].plot(StateData[3],np.array(localData.groupby(\"week\")[\"latentA\"].mean())[0:-2],'bo')\n","axs[1,1].plot(np.diff(StateData[3],n=1),np.array(localData.groupby(\"week\")[\"latentA\"].mean())[0:-3],'bo')\n","axs[1,2].plot(np.diff(StateData[3],n=2),np.array(localData.groupby(\"week\")[\"latentA\"].mean())[0:-4],'bo')\n","\n","axs[2,0].plot(StateData[3],np.array(localData.groupby(\"week\")[\"latentB\"].mean())[0:-2],'bo')\n","axs[2,1].plot(np.diff(StateData[3],n=1),np.array(localData.groupby(\"week\")[\"latentB\"].mean())[0:-3],'bo')\n","axs[2,2].plot(np.diff(StateData[3],n=2),np.array(localData.groupby(\"week\")[\"latentB\"].mean())[0:-4],'bo')"]},{"cell_type":"markdown","metadata":{"id":"ck_Ts_WDwSs4"},"source":["## Pennsylvania"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2022-01-14T00:49:03.974031Z","iopub.status.busy":"2022-01-14T00:49:03.973736Z","iopub.status.idle":"2022-01-14T00:49:05.203007Z","shell.execute_reply":"2022-01-14T00:49:05.202304Z","shell.execute_reply.started":"2022-01-14T00:49:03.973999Z"},"id":"YrH00iynwSs4","trusted":true},"outputs":[],"source":["VMData = NorthDataSet[NorthDataSet[\"Geo_Location\"]==\"USA: Pennsylvania\"]\n","\n","fig,axs = plt.subplots(3,3,figsize=(20,10))\n","\n","for st in StateData:\n","\n","    axs[0,0].plot(st,color=\"gray\")\n","    axs[0,1].plot(np.diff(st,n=1),color=\"gray\")\n","    axs[0,2].plot(np.diff(st,n=2),color=\"gray\")\n","\n","axs[0,0].plot(StateData[8],color=\"red\")\n","axs[0,1].plot(np.diff(StateData[8],n=1),color=\"red\")\n","axs[0,2].plot(np.diff(StateData[8],n=2),color=\"red\")\n","\n","axs[1,0].plot(StateData[8],np.array(localData.groupby(\"week\")[\"latentA\"].mean())[0:-2],'bo')\n","axs[1,1].plot(np.diff(StateData[8],n=1),np.array(localData.groupby(\"week\")[\"latentA\"].mean())[0:-3],'bo')\n","axs[1,2].plot(np.diff(StateData[8],n=2),np.array(localData.groupby(\"week\")[\"latentA\"].mean())[0:-4],'bo')\n","\n","axs[2,0].plot(StateData[8],np.array(localData.groupby(\"week\")[\"latentB\"].mean())[0:-2],'bo')\n","axs[2,1].plot(np.diff(StateData[8],n=1),np.array(localData.groupby(\"week\")[\"latentB\"].mean())[0:-3],'bo')\n","axs[2,2].plot(np.diff(StateData[8],n=2),np.array(localData.groupby(\"week\")[\"latentB\"].mean())[0:-4],'bo')"]},{"cell_type":"markdown","metadata":{"id":"ynOQa4a1wSs4"},"source":["From the selected examples looks like there is a particular correlation between either cases rate or acceleration of the cases and the learned representation. However, this correlation is perhaps hindered by the noise in the acceleration approximation.\n","\n","Although the cross-validation is not optimal and the data set presents geographical and temporal imbalances. The ability to find temporal patterns suggest the existence of such patterns but not the ability to generalize at least with the current configuration.\n","\n","However, is worth mentioning that relational encoding offers a viable solution to encode large sequences and find meaningful patterns using convolutional neural networks. The computer vision approach may favor representations where the sequences share some common global similarity and specific patterns in the sequence might be lost. However relational encoding can also be used for Graph neural networks to identify important node clusters that could lead to specific genomic regions. The continuous development of these models could lead to a better understanding of the Covid-19 pandemic and the introduction of new preventive measures.\n","\n","Further details at https://tavoglc.medium.com/sars-cov-2-classification-with-variational-autoencoders-4842696a43c"]}],"metadata":{"colab":{"provenance":[{"file_id":"https://storage.googleapis.com/kaggle-colab-exported-notebooks/covid-19-sequence-disentangling-with-kl-annealing-70a0dda2-1eb1-4946-b795-847f1072eb8c.ipynb?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com/20240407/auto/storage/goog4_request&X-Goog-Date=20240407T224958Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=9de19ac8e916b7ed7472ab196f2967a82f789ccef68fc08ceabaefb8c7238e5d7dfb977ace7811ed4ed041ffbfb930203cc2f789dea66581ed3a571102ffcf9b2cb800fc91be974a4f9386a694ac1195b1f180b60a43e096b42c415af5fdce394ce012f0a963affa693fd4ee105fe72d747f2913f17e30d65fc5496de5f83b835d73ddf78401f9024dffd191ce80876cf4005704b46a9b63b60921095e2e1db5ca25751b4676af4cb56f518bf528dad6b8bb108840319f55745d482dd7163ab0502b30ade83a8a5707e20b063d85baf9a37064cb3b919068aff6e06a2fd7f7985ea86615451139fbd798ca1dda94e0066f1639864fedb34e7ba931f180c9bae5","timestamp":1712530811236}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":0}
